{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/xiaopeng/.cache/torch/hub/facebookresearch_esm_main\n",
      "Using cache found in /home/xiaopeng/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    }
   ],
   "source": [
    "from scripts.model import SPIRED_Stab\n",
    "import torch\n",
    "\n",
    "# load parameter\n",
    "model = SPIRED_Stab(device_list = ['cpu', 'cpu', 'cpu', 'cpu'])\n",
    "model.load_state_dict(torch.load('data/model/SPIRED-Stab.pth'))\n",
    "model.eval()\n",
    "\n",
    "# load ESM-2 650M model\n",
    "esm2_650M, _ = torch.hub.load('facebookresearch/esm:main', 'esm2_t33_650M_UR50D')\n",
    "esm2_650M.eval()\n",
    "    \n",
    "# load ESM-2 3B model\n",
    "esm2_3B, esm2_alphabet = torch.hub.load('facebookresearch/esm:main', 'esm2_t36_3B_UR50D')\n",
    "esm2_3B.eval()\n",
    "esm2_batch_converter = esm2_alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate variants one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_single(seq, device = 'cpu'):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, target_tokens = esm2_batch_converter([('', seq)])\n",
    "        results = esm2_3B(target_tokens.to(device), repr_layers = range(37), need_head_weights = False, return_contacts = False)\n",
    "        f1d_esm2_3B = torch.stack([v for _, v in sorted(results[\"representations\"].items())], dim = 2)\n",
    "        f1d_esm2_3B = f1d_esm2_3B[:, 1:-1]\n",
    "        f1d_esm2_3B = f1d_esm2_3B.to(dtype = torch.float32)\n",
    "        \n",
    "        result_esm2_650m = esm2_650M(target_tokens.to(device), repr_layers = [33], return_contacts = False)\n",
    "        f1d_esm2_650M = result_esm2_650m['representations'][33][0, 1:-1, :].unsqueeze(0)\n",
    "    \n",
    "    data = {\n",
    "            'target_tokens': target_tokens[:, 1:-1],\n",
    "            'esm2-3B': f1d_esm2_3B,\n",
    "            'embedding': f1d_esm2_650M\n",
    "        }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pred_ddG_dTm(mut_seqs, wt_seqs):\n",
    "    mut_data = [get_data_single(seq) for seq in mut_seqs]\n",
    "    wt_data = [get_data_single(seq) for seq in wt_seqs]\n",
    "\n",
    "    mut_pos_torch_list = [torch.tensor((np.array(list(wt_s)) != np.array(list(mut_s))).astype(int).tolist()) \n",
    "                          for wt_s, mut_s in zip(wt_seq, mut_seq)]\n",
    "\n",
    "    ddG_list = []\n",
    "    dTm_list = []\n",
    "    with torch.no_grad():\n",
    "        for wt_d, mut_d, mut_pos in zip(wt_data, mut_data, mut_pos_torch_list):\n",
    "            ddG, dTm, _, _ = model(wt_d, mut_d, mut_pos)\n",
    "            print(ddG.item(), dTm.item())\n",
    "            ddG_list.append(ddG.item())\n",
    "            dTm_list.append(dTm.item())\n",
    "    return ddG_list, dTm_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.8999999999999998, pvalue=0.03738607346849874)\n",
      "PearsonRResult(statistic=0.8835027286968199, pvalue=0.046888792768475386)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "df_protherm_mm = pd.read_csv('data/protherm_multiple.csv')\n",
    "mut_seq = df_protherm_mm.mut_seq[:5]\n",
    "wt_seq = df_protherm_mm.wt_seq[:5]\n",
    "\n",
    "ddG_list, dTm_list = pred_ddG_dTm(mut_seq, wt_seq)\n",
    "\n",
    "target = df_protherm_mm['ddg'][:5]\n",
    "print(spearmanr(target, ddG_list))\n",
    "print(pearsonr(target, dTm_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "savinase = 'AQSVPWGISRVQAPAAHNRGLTGSGVKVAVLDTGISTHPDLNIRGGASFVPGEPSTQDGNGHGTHVAGTIAALNNSIGVLGVAPSAELYAVKVLGASGSGSVSSIAQGLEWAGNNGMHVANLSLGSPSPSATLEQAVNSATSRGVLVVAASGNSGAGSISYPARYANAMAVGATDQNNNRASFSQYGAGLDIVAPGVNVQSTYPGSTYASLNGTSMATPHVAGAAALVKQKNPSWSNVQIRNHLKNTATSLGSTNLYGSGLVNAEAATR'\n",
    "\n",
    "df_stab_mm = pd.read_csv('data/stab_data_bsj_r1.csv')\n",
    "\n",
    "mut_seq = df_stab_mm.seq\n",
    "wt_seq = [savinase] * len(mut_seq)\n",
    "\n",
    "ddG_list, dTm_list = pred_ddG_dTm(mut_seq, wt_seq)\n",
    "\n",
    "target = df_stab_mm['Stability']\n",
    "\n",
    "print(spearmanr(target, ddG_list))\n",
    "print(pearsonr(target, dTm_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spired_fitness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
